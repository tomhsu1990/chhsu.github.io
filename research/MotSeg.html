<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)

	Updated: Ching-Hsiang Hsu 2024/12/29
	Notes: moduleration
-->
<html>
	<head>
		<title>Motion Segmentation</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<div id="header-placeholder"></div>

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Motion and Semantic Segmentation</h1>
										<p> 
											<ol>
												Advised by: Prof. <a href="https://sites.google.com/site/chiehchihbobwang/">Chieh-Chih (Bob) Wang</a><br>
												Date: July 2013 - July 2014<br><br>
												In robotics applications involving data from a moving camera—such as navigation, tracking, and localization—it is inevitable to encounter multiple moving objects. As a result, motion segmentation becomes a critical task to enhance the performance of these operations. Our goal is to partition regions in an RGB-D image that share the same estimated motion in 6 degrees of freedom (6 DoF). Additionally, we incorporated the concept of physical support to improve the accuracy and understanding of the motion segments.
											</ol>
										</p> 
									</header>


									<hr class="major" />
									<header class="main">
										<h2>Motion and Semantic Segmentation in Crowded Urban Areas with a Moving RGB-D Camera</h2>
									</header>
									<p>
										<div class="row">
											<div class="col-6 col-12-medium">
												<center>
												<a href="./img/MotSeg2.png" class="image"><img src="./img/MotSeg2.png" alt="" style="width: 100%; height: 100%;"/></a>
												</center>
											</div>
											<div class="col-6 col-12-medium">
												<div class="video-container">
													<p align="center">
														<iframe width="640" height="480"
															src="https://www.youtube.com/embed/5n8fD35tHek" frameborder="0" allowfullscreen>
														</iframe>
													</p>
												</div>
											</div>
										</div>
									</p>
									<p>
										We propose a novel and robust motion segmentation algorithm leveraging RGB-D video captured with a structured light camera. Using a modified Random Sample Consensus (RANSAC) algorithm, we estimate motion by exploiting the coherence of color and spatial relationships in the scene. This approach inherits the computational efficiency and probabilistic robustness of the RANSAC paradigm. After aligning two point clouds using the estimated transformation, we utilize the distribution of inliers and outliers as prior knowledge for graph-cut-based segmentation.<br><br>
										To further enhance the understanding of motion segments, we integrate the concept of physical support relationships, allowing us to capture meaningful interactions between motion segments. Additionally, we provide a comprehensive annotated RGB-D dataset captured in a crowded urban environment to validate our method. Comparisons with existing motion segmentation approaches demonstrate the superior performance of our method in highly dynamic scenes, particularly in accurately handling challenging scenarios such as occlusions and complex motions.
									</p>
									<p>
										<a href="./paper/MotSeg.pdf"><i>Ching-Hsiang Hsu, "Graph-cut based Motion Segmentation with Physical Support Relationships in Crowded Urban Areas from a Moving RGB-D Camera," National Taiwan University Thesis Press, July, 2014.</i></a>
									</p>

									<hr class="major" />
									<header class="main">
										<h2>Interactive Image Segmentation</h2>
										<ol>
											Date: Apr. 2013 - June 2013
										</ol>
									</header>
									<p>
										<center>
											<a href="./img/interactive_seg.jpg" class="image"><img src="./img/interactive_seg.jpg" alt="" style="width: 80%; height: 80%; margin:auto;"/></a>
										</center>
									</p>
									<p>
										In the motion segmentation section, two key techniques used for segmentation are graph-cut optimization and Simple Linear Iterative Clustering (SLIC). I initially experimented with these methods in interactive image segmentation. The process involves using a red pen to annotate regions of interest and a blue pen for regions of non-interest. By applying the max-flow algorithm, the regions are effectively separated based on the annotations. This approach is straightforward to implement and delivers impressive performance.
									</p>

									<hr class="major" />
									<p>
										<i>We keep moving forward, opening new doors, and doing new things, because we're curious and curiosity keeps leading us down new paths.</i>
									</p>
									<p style="text-align:right">- Walt Disney</p>


								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<div id="menu-placeholder"></div>

							<!-- Section -->
								<div id="contact-placeholder"></div>

							<!-- Footer -->
								<div id="footer-placeholder"></div>
						</div>
					</div>
			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>