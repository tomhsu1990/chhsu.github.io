<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)

	Updated: Ching-Hsiang Hsu
-->
<html>
	<head>
		<title>Social Action Recognition</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<div id="header-placeholder"></div>

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Social Action Recognition in Egocentric RGB-D Videos</h1>
										<p> 
											<ol>
												Advised by: Prof. <a href="https://sites.google.com/site/chiehchihbobwang/">Chieh-Chih (Bob) Wang</a><br>
												Date: Mar. 2014 - June 2014<br><br>
												Wearable computing has gained significant attention in recent years, with first-person vision emerging as a critical machine perception technique for enabling advanced wearable applications. In our work, we address the challenge of egocentric social action recognition using an RGB-D structured light camera.
											</ol>
										</p> 
									</header>

									<hr class="major" />
									<p>
										<div class="row">
											<div class="col-6 col-12-medium">
												<p>
													Our proposed method achieved a <b>94%</b> recognition accuracy on a dataset of 65 RGB-D videos. The action recognition process consists of two main steps. First, we extract 3D trajectories of moving parts corresponding to five types of social actions captured from an egocentric RGB-D camera. Next, we reduce the dimensionality of the extracted data to facilitate training and testing, and apply a multi-classification tree for classification.
												</p>
											</div>
											<div class="col-6 col-12-medium">
												<center>
												<a href="./img/first_person.jpg" class="image"><img src="./img/first_person.jpg" alt="" width="100%" height="100%"/></a>
												</center>
											</div>
										</div>
									</p>
									<p>
										<a href="./paper/first_person.pdf"><i>Ching-Hsiang Hsu, Kung-Hung Lu, Zhiqiang Zhong and Chieh-Chih Wang, "Social Action Recognition in Egocentric RGB-D Videos," Proceedings of the 27th IPPR Conference on Computer Vision, Graphics and Image Processing (CVGIP), August 2014.</i></a>
									</p>

									<hr class="major" />
									<p>
										<i>Action speaks louder than words but not nearly as often.</i> - Mark Twain
									</p>

								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<div id="menu-placeholder"></div>

							<!-- Section -->
								<div id="contact-placeholder"></div>

							<!-- Footer -->
								<div id="footer-placeholder"></div>
						</div>
					</div>
			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>